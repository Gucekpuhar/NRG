

close all

clear all

clc


im = imread('im1.jpg');
figure, imshow(im);

% median filter - rgb.
b = medfilt2(double(im(:,:,3)), [3,3]);
r = medfilt2(double(im(:,:,1)), [3,3]); 
g = medfilt2(double(im(:,:,2)), [3,3]);


%% sence:

sence = ((4/pi).*atan(((b-g))./(b+g)));
figure, imshow(sence , []); colormap(jet); colorbar;

% določi threshold
shadow_mask = shadow_ratio>0.25;
figure, imshow(shadow_mask, []); 

shadow_mask(1:5,:) = 0;
shadow_mask(end-5:end,:) = 0;
shadow_mask(:,1:5) = 0;
shadow_mask(:,end-5:end) = 0;


% velikost senc threshold
shadow_mask = bwareaopen(shadow_mask, 100);


[x,y] = find(imdilate(shadow_mask,strel('disk',2))-shadow_mask);


figure, imshow(im); hold on,
plot(y,x,'.b'), title('Shadow Boundaries');

%% odstrani

%% daj v hsv izracunaj v dela ki ni v senci (maski) in v maski spremeni v vrednost



alternativa



    YCBCR = rgb2ycbcr(I);
    IY = YCBCR(:,:,1);
    ICb = YCBCR(:,:,2);
    ICr = YCBCR(:,:,3);
    Yavg = mean2(IY);
    mask = zeros(size(IY));
    for i = 1:size(IY,1);
        for j = 1:size(IY,2);        
            pixel = IY(i,j);                    
            if(pixel > Yavg) %black
                newpixel = 0;
            else  %white
                newpixel = 1;
            end
            mask(i,j) = newpixel;
        end
    end
    maskbw = mask;
    mask = uint8(maskbw);
    figure,imshow(mask)

    se = [0 1 1 1 0; 1 1 1 1 1; 1 1 1 1 1; 1 1 1 1 1; 0 1 1 1 0];   
    % mask morphological operation
    shadow_core = uint8(imerode(mask, se));
    nonshadow_core = uint8(imerode(1-mask, se));
%     figure,subplot(1,2,1),imshow(shadow_core)
%            subplot(1,2,2),imshow(nonshadow_core)   
        % mean channel values in YCbCr
        shadowavg_Y = sum(sum(IY.*shadow_core)) / sum(sum(shadow_core));
        shadowavg_Cb = sum(sum(ICb.*shadow_core)) / sum(sum(shadow_core));
        shadowavg_Cr = sum(sum(ICr.*shadow_core)) / sum(sum(shadow_core));
        nonshadowavg_Y = sum(sum(IY.*nonshadow_core)) / sum(sum(nonshadow_core));
        nonshadowavg_Cb = sum(sum(ICb.*nonshadow_core)) / sum(sum(nonshadow_core));
        nonshadowavg_Cr = sum(sum(ICr.*nonshadow_core)) / sum(sum(nonshadow_core));        
        % computing ratio, and difference in ycbcr space
        diff_Y = nonshadowavg_Y - shadowavg_Y;
        ratio_Cb = nonshadowavg_Cb/shadowavg_Cb;
        ratio_Cr = nonshadowavg_Cr/shadowavg_Cr;
        % y channel additive correction
        % cb, and cr channels correction
        Y = IY + mask * diff_Y;
        Cb = ICb.*(1-mask) + mask.*ratio_Cb.*ICb;
        Cr = ICr.*(1-mask) + mask.*ratio_Cr.*ICr;      
        %merge 3 channels
        shadows_remove = cat(3,Y,Cb,Cr);
        %convert back 
        shadows_remove = ycbcr2rgb(shadows_remove);
        figure,imshow(shadows_remove)

--------------------------------------------------------------------------------------
alternativa




imgGray = rgb2gray(img);

r = 2;
deltaLines = cat(2, repmat(r.*cos(potShadowLines(:, 5)+pi/2), 1, 2), repmat(r.*sin(potShadowLines(:, 5)+pi/2), 1, 2));
newLinesRight = potShadowLines(:, 1:4) + deltaLines;
newLinesLeft = potShadowLines(:, 1:4) - deltaLines;

meanRightInt = medianLineIntensity(imgGray, newLinesRight, 'nearest');
meanLeftInt = medianLineIntensity(imgGray, newLinesLeft, 'neraest');

minInt = min([meanLeftInt meanRightInt], [], 2);
maxInt = max([meanLeftInt meanRightInt], [], 2);

shadowAbsFeatures = cat(2, minInt, maxInt);

% re-scale with respect to min/max of the scene indensities

prctileT = 3;
sceneMin = prctile(imgGray(sceneMask>0), prctileT);
sceneMax = prctile(imgGray(sceneMask>0), 100-prctileT);

minInt = (minInt-sceneMin)./(sceneMax-sceneMin);
maxInt = (maxInt-sceneMin)./(sceneMax-sceneMin);

% cluster them in 3 groups: reflectance edges in shadow and light, and shadow edges
% oversegment a little bit for more robustness?
shadowFeatures = cat(2, minInt, maxInt);

if size(shadowFeatures,1) > 5
    [clusterInd, cx] = kmeans(shadowFeatures, 4, 'Replicates', 20);
else
    clusterInd = 1; cx = shadowFeatures;
end

% figure out which of them are shadows (simple threshold, but would be better to learn)
shadowClusters = cat(2, cx(:,1), cx(:,2)-cx(:,1));

--------------------------------------------------------------------------


verbose = 1;
imgName = 'img';

% load the image
imgFilename = fullfile('data', 'img', sprintf('%s.jpg', imgName));
img = im2double(imread(imgFilename));

% load the classifier
classifierInfo = load('data/bdt-eccv10.mat');

% whether we should use the geometric context ground probability or not
useGroundProb = 1;
if useGroundProb
    % the variable 'groundProb' was pre-computed using geometric context,
    % see README.txt
    groundProbFilename = fullfile('data', 'img', sprintf('%s-groundProb.mat', imgName));
    
    if exist(groundProbFilename, 'file')
        load(groundProbFilename, 'groundProb');
        myfprintf(verbose, 'Successfully loaded ground probability.\n');
    else
        myfprintf(verbose, 'Warning: you specified useGroundProb = 1, but I couldn''t find the corresponding file %s!\n', groundProbFilename);
        myfprintf(verbose, 'I will keep going, but won''t be using the ground probability.\n');
        groundProb = [];
        useGroundProb = 0;
    end
else
    groundProb = [];
end

% load texton dictionary and filter bank
univTextons = load('data/univTextons_128.mat');
textonFilterBank = load('data/filterBank.mat');

%%

% parameters for the CRF
lambda = 0.5;
beta = 16;

%% boundaries
myfprintf(verbose, 'Finding image boundaries...\n');
[boundaries, junctions, neighbors, fseg] = extractImageBoundaries(img);

% display them
figure(1); imshow(img);
displayBoundaries(figure(1), boundaries, 'b', 3);
title(sprintf('Oversegmentation, %d boundaries found', length(boundaries)));

%% boundary features
myfprintf(verbose, 'Computing boundary features (this will take a while...)\n');
bndFeatures = computeAllShadowBoundaryFilterFeatures(img, boundaries, ...
    'Verbose', verbose, ...
    'RGBFilters', 1, 'LABFilters', 1, 'ILLFilters', 1, 'NbScales', 4, ...
    'Textons', 1, 'UnivTextons', univTextons.clusterCenters, 'TextonFilterBank', textonFilterBank.filterBank);

%% Compute image features (unused)
myfprintf(verbose, 'Computing image features...\n');
imageFeatures = computeImageFeatures(img, 'Verbose', verbose, 'RGBContrast', 1);

%% Run the boundary classifier
myfprintf(verbose, 'Applying boundary classifier...\n');

[boundaryProbabilities, indStrongBnd, allBoundaryProbabilities] = applyLocalBoundaryClassifier(img, [], ...
    classifierInfo, bndFeatures, imageFeatures, ...
    boundaries, neighbors.junction_fragmentlist, neighbors.fragment_junctionlist);

% Let's display them
figure(2); imshow(img);
displayBoundariesProb(figure(2), boundaries(indStrongBnd), boundaryProbabilities, 3);
title('Boundary probability (for strong boundaries only)');

%% Run CRF

% compute segment features
spFeatures = computeShadowSegmentFeatures(img, fseg, 'RGBHist', 1);
spFeats = spFeatures.RGBHist.mean;

withStr = {'without', 'with'};
myfprintf(verbose, 'Applying CRF %s geometric context...\n', withStr{useGroundProb+1});
boundaryLabels = applyBoundaryGrouping(lambda, beta, boundaries, neighbors.junction_fragmentlist, ...
    'UseShadowProbability', 1, 'ShadowProb', boundaryProbabilities, 'ShadowProbInd', indStrongBnd, ...
    'UseGroundProbability', useGroundProb, 'GroundMask', groundProb, ...
    'UseSegFeatures', 1, 'SegFeatures', spFeats, 'BndToSegId', neighbors.fragment_segments);

%CRF labels
figure(3); imshow(img);
displayBoundaries(figure(3), boundaries(boundaryLabels==0), 'r', 3);
groundStr = {'Shadows', 'Ground shadows'};
title(sprintf('%s detected', groundStr{useGroundProb+1}));


--------------------------------------------


clear all;
close all;
clc;

% image setup
filename = 'adelson2.jpg'; % test Image is from IPOL
scale = 'log'; % linear or log image prescaling (gamma correction)
dwnsample = 1; % downsampling factor for speed

% Model parameters
p = 0; % L1-based retinex
lambda = 0.15; % pick a filter parameter / threshold
alpha = 0.01; % weight of additional term L2(r)
beta = 0; % weight of additional term L2(r-i)
rho = 0.10; % penalty weight for ADMM
inner = 150; % maximum number of inner ADMM iterations
relTol = 1e-4; % relative tolerance for L0/L1 optimization
pcgTol = 1e-6; % PCG-tolerance for L0/L1 optimization
filter = 'hard'; % Morel-like hard thresholding



%% preprocessing


% image loading
I = double(imread(filename));
I = mean(I,3);

% downsample, normalize and log-convert 
I = downsample(I', dwnsample);
I = downsample(I', dwnsample);

I = I/max(I(:));

im = I;

switch scale
    case 'log'
        I = log(0.1+255*I);
    case 'linear'
        I = I*5.5;
end


% weight 1 -- sparsity of gradients within same color
w1 = weights_local(I);

% weight 2 -- fidelity with semi-local Gaussian weights
w2 = w1;

% w = max(w2,w1)
W = max(w1,w2);

% selecting and preparing the gradient filter function / adaptive threshold
[f,tau] = gradient_filter(filter,w1,w2,lambda);



%% main computation

% Gradient Fitting
switch p
    case 0
        r = L0_retinex_solver( W, alpha, beta, f, tau, I(:), rho, inner, relTol, pcgTol );
    case 1
        r = L1_retinex_solver( W, alpha, beta, f, tau, I(:), rho, inner, relTol, pcgTol );
    case 2
        r = L2_retinex_solver( W, alpha, beta, f, tau, I(:) );
end

% reshape
r = reshape(r,size(I));




%% postprocessing

% compute difference before/after retinex
s = (I - r);
s = exp(s);
s = ((s-min(s(:)))/(max((s(:)))-min(s(:))));


% recovered reflectance clip outliers
r = exp(r);
o = ((r-min(r(:)))/(max((r(:)))-min(r(:))));


%% Visualization
figure();

% input image
subplot(131);
imshow(im/max(im(:))); title('Input');

% Shading
subplot(132);
imshow(imadjust(s)); title('Shading');

% Output
subplot(133);
imshow(imadjust(o)); title('Retinex');